fix_seed: 0
checkpoints_every: 1024
tensorboard_log: True
tqdm_progress_bar: False
result_path: ./results/gcpnet_vqvae/
normalizer_path: ./data/normalizer.pkl

resume:
  enabled: False
  resume_path: results/gcpnet_vqvae/2025-04-21__22-18-14/checkpoints/best_valid.pth
  restart_optimizer: True

model:
  compile_model: False
  max_length: 128
  decoder_output_scaling_factor: 1  # Added scaling factor for backbone prediction outputs
  use_ndlinear: False  # Toggle for using NdLinear instead of Conv1d layers
  encoder:
    name: gcpnet # gvp_transformer, gcpnet
    pretrained:
      enabled: True
      config_path: ./configs/pretrained/structure_denoising_pretrained_config.yaml
      checkpoint_path: ./models/checkpoints/structure_denoising/gcpnet/ca_bb/last.ckpt # define your checkpoint directory here
  decoder: geometric_decoder # geometric_decoder, gcpnet
  vqvae:
    positional_encoding: True
    causal_attention: True
    vector_quantization:
      dim: 768
      decay: 0.8
      codebook_size: 256
      commitment_weight: 1.0
      alpha: 1.0
    encoder:
      dimension: 768
      num_heads: 16
      num_blocks: 8
    decoder:
      dimension: 768
      num_heads: 16
      num_blocks: 4

train_settings:
  data_path: /mnt/hdd8/mehdi/datasets/vqvae/uniref_50/
  num_epochs: 1024
  shuffle: True
  loss: crossentropy
  sample_weight: False
  mixed_precision: fp16 # no, fp16, bf16, fp8
  save_pdb_every: 16
  batch_size: 32
  num_workers: 8
  grad_accumulation: 1
  max_task_samples: 256000
  profiler_log_dir: ./log/torch_profiler_pretrained_gcpnet
  profile_train_loop: False
  cutoff_augmentation:
    enabled: True
    probability: 0.5
    min_length: 25
  gradient_norm_logging_freq: 50  # How often to calculate and log gradient norm (in steps)
  losses:
    alignment_strategy: kabsch # kabsch, kabsch_old, quaternion, no
    mse:
      enabled: False
      weight: 0.01
    backbone_distance:
      enabled: True
      weight: 1.0
    backbone_direction:
      enabled: True
      weight: 1.0
    binned_distance_classification:
      enabled: False
      weight: 0.01
    binned_direction_classification:
      enabled: False
      weight: 0.01
    inverse_folding:
      enabled: False
      weight: 1.0
    fape:
      enabled: False
      weight: 1.0
      clamp_distance: 10.0
      length_scale: 10.0

valid_settings:
  data_path: /mnt/hdd8/mehdi/datasets/vqvae/validation_set_1024_h5
  do_every: 4
  save_pdb_every: 16
  batch_size: 16
  num_workers: 0

visualization_settings:
  data_path: /mnt/hdd8/mehdi/datasets/vqvae/validation_set_1024_h5
  fasta_path: ../../visualization/Rep_subfamily_basedon_S40pdb.fa
  do_every: 8192
  batch_size: 1
  num_workers: 4

optimizer:
  name: schedulerfree
  lr: 5e-5
  weight_decouple: True
  weight_decay: 1e-2
  eps: 1e-16
  beta_1: 0.9
  beta_2: 0.999
  use_8bit_adam: False
  grad_clip_norm: 1
  decay:
    warmup: 1024
    min_lr: 1e-7
    gamma: 0.2
    num_restarts: 1
