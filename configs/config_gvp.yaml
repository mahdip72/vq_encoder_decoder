fix_seed: 0
checkpoints_every: 32
tensorboard_log: True
tqdm_progress_bar: True
result_path: ./results/gvp
normalizer_path: /mnt/hdd8/mehdi/projects/vq_encoder_decoder/data/normalizer.pkl

resume:
  resume: False
  resume_path: ./path/to/checkpoint.pth
  restart_optimizer: True

model:
  compile_model: False
  max_length: 1024
  struct_encoder:
    enable: False
    use_rotary_embeddings: True
    use_foldseek: True
    use_foldseek_vector: True
    gvp_num_layers: 3
    top_k: 30 #default 30 The number of edges to draw per node (as destination node).
    num_rbf: 16   #default 16
    num_positional_embeddings: 16  #default 16
    node_h_dim: (100,32) #default (100,32)
    edge_h_dim: (32,1)   #default (32,1)
    use_seq:
       enable: False
       seq_embed_mode: "embedding" #"embedding","ESM2"
       seq_embed_dim: 20 #1280 for ESM2
    fine_tune:
      enable: False
      last_layers_trainable: 2
  vqvae:
    vector_quantization:
      dim: 128
      codebook_size: 256
      decay: 0.8
      commitment_weight : 1.0
      alpha: 2.0
    encoder:
      dimension: 320
      dim_feedforward: 640
      num_heads: 4
      num_layers: 4
      activation_function: gelu
    decoder:
      dimension: 320
      dim_feedforward: 640
      num_heads: 4
      num_layers: 4
      activation_function: gelu

train_settings:
  data_path: /home/mpngf/datasets/vqvae/swissprot_1024_h5/
  num_epochs: 128
  shuffle: True
  loss: crossentropy
  sample_weight: True
  mixed_precision: fp16 # no, fp16, bf16, fp8
  device: cuda
  batch_size: 256
  num_workers: 6
  grad_accumulation: 1
  max_task_samples: 100000

valid_settings:
  data_path: H:\Datasets\Joint_training
  do_every: 1
  batch_size: 1
  device: cuda
  num_workers: 0

optimizer:
  name: adam
  lr: 1e-4
  weight_decouple: True
  weight_decay: 1e-2
  eps: 1e-16
  beta_1: 0.9
  beta_2: 0.999
  use_8bit_adam: False
  grad_clip_norm: 1
  decay:
    warmup: 0
    min_lr: 5e-6
    gamma: 0.2
    num_restarts: 1